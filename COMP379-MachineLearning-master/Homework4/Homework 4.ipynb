{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier -- Homework 4\n",
    "\n",
    "### Basic Information:\n",
    "IMDb Database used. There are two files from a separate repository: Positive Reviews and Negative Reviews \n",
    "\n",
    "##### Split the dataset into \n",
    "- 70% for the training set\n",
    "- 15% for the development set\n",
    "- 15% for the test set\n",
    "\n",
    "Build a binary classifier to perform the movie review classification automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mary B. Makarious\n",
    "# Homework 4 -- IMDb Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Packages \n",
    "\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Keep everything in Jupyter\n",
    "%matplotlib inline \n",
    "\n",
    "# Ignore several specific Pandas warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Data\n",
    "- Split them by line\n",
    "- Add to a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "\n",
    "positiveFile = open(\"rt-polarity.pos\",\"r\")\n",
    "positiveReviews = positiveFile.read()\n",
    "positiveReviews = positiveReviews.lower()\n",
    "positiveReviews = positiveReviews.split(\"\\n\")\n",
    "\n",
    "negativeFile = open(\"rt-polarity.neg\",\"r\")\n",
    "negativeReviews = negativeFile.read()\n",
    "negativeReviews = negativeReviews.lower()\n",
    "negativeReviews = negativeReviews.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging\n",
    "- Merge all the reviews into 2 lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Reviews:  10664\n"
     ]
    }
   ],
   "source": [
    "movie_ratings = []\n",
    "for i in range(0, len(positiveReviews)):\n",
    "    movie_ratings.append('pos')\n",
    "for i in range(0, len(negativeReviews)):\n",
    "    movie_ratings.append('neg')\n",
    "\n",
    "movie_reviews = []\n",
    "movie_reviews = positiveReviews + negativeReviews\n",
    "reviews = []\n",
    "for i in range(0, len(movie_reviews)):   \n",
    "    if movie_ratings[i] == 'pos':\n",
    "        category = \"pos\"\n",
    "        value = movie_reviews[i]\n",
    "    else: \n",
    "        category = \"neg\"\n",
    "        value = movie_reviews[i]\n",
    "        \n",
    "    reviews.append((category, value))\n",
    "\n",
    "print (\"Length of Reviews: \", len(reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling\n",
    "- Shuffle the index values \n",
    "- Split the data into the train, development, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training Set:  7465\n",
      "Length of Development Set:  1600\n",
      "Length of Test Set:  1599\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(reviews)\n",
    "\n",
    "split = round(len(reviews)*.70)\n",
    "split2 = round(len(reviews)*.15)\n",
    "\n",
    "train_set = reviews[0:split]\n",
    "del reviews[0:split]\n",
    "\n",
    "development_set = reviews[0:split2]\n",
    "del reviews[0:split2]\n",
    "\n",
    "test_set = reviews[0:split2]\n",
    "\n",
    "print (\"Length of Training Set: \", len(train_set))\n",
    "print (\"Length of Development Set: \",len(development_set))\n",
    "print (\"Length of Test Set: \",len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "These serve the following purposes: \n",
    "- Removing punctuation\n",
    "- Removing the whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'to': 2, 'the': 2, '': 1, 'jeanclaud': 1, 'hes': 1, 'damme': 1, 'that': 1, 'than': 1, 'van': 1, 'centurys': 1, 'and': 1, 'arnold': 1, 'is': 1, 'splash': 1, 'make': 1, 'schwarzenegger': 1, 'conan': 1, 'segal': 1, 'a': 1, 'going': 1, 'rock': 1, '21st': 1, 'or': 1, 'new': 1, 'steven': 1, 'greater': 1, 'even': 1, 'be': 1, 'destined': 1})\n"
     ]
    }
   ],
   "source": [
    "def removePunctuation(data):\n",
    "    table = data.translate(str.maketrans(\"\", \"\", string.punctuation)) \n",
    "    return table\n",
    "\n",
    "def postPunctuationTrimming(data):\n",
    "    data = removePunctuation(data)\n",
    "    data = data.lower()\n",
    "    return re.split(\"\\W+\", data)\n",
    "\n",
    "# Testing out the Helper Functions\n",
    "# Optional \n",
    "\n",
    "trimFunction = postPunctuationTrimming(positiveReviews[0])\n",
    "counter = Counter(trimFunction)\n",
    "\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "- Count the words\n",
    "- Assosciating the words with their prior probabilities and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordcollection = {}\n",
    "word_count = {\"pos\": {}, \"neg\": {}}\n",
    "priorProb = {\"pos\" : 0., \"neg\" : 0.}\n",
    "documents = []\n",
    "\n",
    "for i in range(0, len(train_set)):   \n",
    "    category = train_set[i][0]\n",
    "    indexValue = train_set[i][1]\n",
    "        \n",
    "    documents.append((category, indexValue))\n",
    "    \n",
    "    priorProb[category] += 1\n",
    "    \n",
    "    words = postPunctuationTrimming(indexValue)\n",
    "    \n",
    "    counts = Counter(words)\n",
    "    \n",
    "    for word, count in counts.items():\n",
    "        if word not in wordcollection:\n",
    "            wordcollection[word] = 0.0 \n",
    "        if word not in word_count[category]:\n",
    "            word_count[category][word] = 0.0\n",
    "        wordcollection[word] += count\n",
    "        word_count[category][word] += count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Predictions \n",
    "##### This predict function takes in the reviews one at a time and implements the Naive Bayes algorithm to predict the labels based on the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Predict(data):\n",
    "    movie_scores = []\n",
    "    for i in range(0, len(data)):\n",
    "        words = postPunctuationTrimming(data[i][1])\n",
    "        counts = Counter(words)\n",
    "    \n",
    "# Probability of the word being positive or negative \n",
    "        priorProb_pos = (priorProb[\"pos\"] / sum(priorProb.values()))\n",
    "        priorProb_neg = (priorProb[\"neg\"] / sum(priorProb.values()))\n",
    "\n",
    "        logProb_positive = 0.0\n",
    "        logProb_negative = 0.0\n",
    "\n",
    "        for words, count in counts.items():\n",
    "            if not words in wordcollection or len(words) <=2:\n",
    "                continue\n",
    "            probWord = wordcollection[words] / sum(wordcollection.values())\n",
    "            probWord_givePositive = word_count[\"pos\"].get(words, 0.0) / sum(word_count[\"pos\"].values())\n",
    "            probWord_giveNegative = word_count[\"neg\"].get(words, 0.0) / sum(word_count[\"neg\"].values())\n",
    "    \n",
    "            if probWord_givePositive > 0:\n",
    "                logProb_positive += math.log(count * probWord_givePositive / probWord)\n",
    "            if probWord_giveNegative > 0:\n",
    "                logProb_negative += math.log(count * probWord_giveNegative / probWord)\n",
    "        \n",
    "        positiveScore = math.exp(logProb_positive + math.log(priorProb_pos))\n",
    "        negativeScore = math.exp(logProb_negative + math.log(priorProb_neg))                  \n",
    "    \n",
    "        if positiveScore > negativeScore:\n",
    "            movie_scores.append(\"pos\")\n",
    "        else:\n",
    "            movie_scores.append(\"neg\")\n",
    "            \n",
    "# Return the movie scores\n",
    "    return movie_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and f1 Scores -- for Development Set\n",
    "Initial labels are taken in, then a 0 or 1 is given in order to be used to find f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Development Set:  0.764375\n",
      "f1 score for Development Set:  0.762743864065\n"
     ]
    }
   ],
   "source": [
    "initialLabel = []\n",
    "binaryLabel = []\n",
    "binaryPredictions = []\n",
    "for l in range(0, len(development_set)):\n",
    "    initialLabel.append(development_set[l][0])\n",
    "predictions = Predict(development_set)\n",
    "\n",
    "for l in range(0, len(development_set)):\n",
    "    if initialLabel[l] == 'pos':\n",
    "        binaryLabel.append(1)\n",
    "    else:\n",
    "        binaryLabel.append(0)\n",
    "\n",
    "for l in range(0, len(development_set)):\n",
    "    if predictions[l] == 'pos':\n",
    "        binaryPredictions.append(1)\n",
    "    else:\n",
    "        binaryPredictions.append(0)        \n",
    "\n",
    "print(\"Accuracy for Development Set: \" , accuracy_score(initialLabel, predictions))\n",
    "print(\"f1 score for Development Set: \" , f1_score(binaryLabel, binaryPredictions, average = 'binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and f1 Scores -- for Test Set\n",
    "Initial labels are taken in, then a 0 or 1 is given in order to be used to find f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test Set:  0.759849906191\n",
      "f1 score for Test Set:  0.754161331626\n"
     ]
    }
   ],
   "source": [
    "initialLabel = []\n",
    "binaryLabel = []\n",
    "binaryPredictions = []\n",
    "for l in range(0, len(test_set)):\n",
    "    initialLabel.append(test_set[l][0])\n",
    "\n",
    "predictions = Predict(test_set)\n",
    "\n",
    "for l in range(0, len(test_set)):\n",
    "    if initialLabel[l] == 'pos':\n",
    "        binaryLabel.append(1)\n",
    "    else:\n",
    "        binaryLabel.append(0)\n",
    "\n",
    "for l in range(0, len(test_set)):\n",
    "    if predictions[l] == 'pos':\n",
    "        binaryPredictions.append(1)\n",
    "    else:\n",
    "        binaryPredictions.append(0)        \n",
    "\n",
    "print(\"Accuracy for Test Set: \" , accuracy_score(initialLabel, predictions))\n",
    "print(\"f1 score for Test Set: \" , f1_score(binaryLabel, binaryPredictions, average = 'binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
