{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChiPy/ACM 2017 ICA demonstrations\n",
    "## Jupyter notebook available at http://chipy2017.pacsites.org\n",
    "\n",
    "1. Blind source separation demo (the cocktail party problem) - Jorge Yanar\n",
    "2. ICA used in artifact removal (e.g., line noise or eye blinks from EEG) - Pavan Ramkumar\n",
    "3. How it works - an \"intuitive\", geometric demo of ICA - Mark V. Albert\n",
    "4. What ICA can tell us about how the brain processes sensory information - Anne Zhao\n",
    "\n",
    "*(thanks to Jason Moss and Ashley Purdy from Metis https://www.thisismetis.com for covering\n",
    "food and drink for this event)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# packages used among multiple sections\n",
    "\n",
    "import sklearn.decomposition # For FastICA and PCA\n",
    "from IPython.display import Image, Audio\n",
    "\n",
    "# setting up interactive plotting\n",
    "import pylab as py\n",
    "# to show plots directly in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "# just changes precision for printing, easier on the eyes\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True) # to supress exponential notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blind Source Separation\n",
    "\n",
    "It's often important to isolate what is important to us from background noise.\n",
    "This is especially the case in voice recognition where we want to isolate the\n",
    "speaker from the surrounding noise to improve recognition accuracy\n",
    "\n",
    "let's step through an example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(filename=\"slides/bss_intro.jpg\",width=\"80%\")\n",
    "# pic from the Interactive Audio Lab at Northwestern with Jinyu Han, Zafar Rafii, Bryan Pardo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the original music\n",
    "Audio(\"data/bss_sounds/bach.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the original speaker\n",
    "Audio(\"data/bss_sounds/speech.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the toy problem: simulating mixing of sounds by multiple microphones in a room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# time to mix the sounds and create the wav\n",
    "\n",
    "# import to be able to work with wave files\n",
    "import scipy.io.wavfile as wave\n",
    "\n",
    "# read in the wave files - results should be int16 type\n",
    "(rate, bach_data) = wave.read('data/bss_sounds/bach.wav')\n",
    "(rate, speech_data) = wave.read('data/bss_sounds/speech.wav')\n",
    "\n",
    "# make mix1 at a 1:1 ratio\n",
    "mix1 = 0.5 * speech_data + 0.5 * bach_data\n",
    "wave.write('results/mix1.wav',rate, np.asarray(mix1,dtype=np.int16))\n",
    "\n",
    "# make mix 2 at a 3:1 ratio, speech to bach\n",
    "mix2 =  1 * speech_data + 0.333 * bach_data\n",
    "wave.write('results/mix2.wav',rate, np.asarray(mix2,dtype=np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the first microphone\n",
    "# (mixed at a ratio of 1:1)\n",
    "Audio(\"results/mix1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the second microphone\n",
    "# (mixed at a ratio of 3:1 speech to bach\n",
    "Audio(\"results/mix2.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note, all the remaining code does not know anything about the original sounds\n",
    "### or how they were mixed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the mixed sounds\n",
    "(rate, mix1) = wave.read('results/mix1.wav')\n",
    "(rate, mix2) = wave.read('results/mix2.wav')\n",
    "\n",
    "# put into 2D array/matrix form with dimensions: samples x 2\n",
    "mixed_X = np.transpose(np.stack((mix1,mix2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now to unmix! Look, it only takes 2 lines.\n",
    "ica = sklearn.decomposition.FastICA(n_components=2)\n",
    "unmixed_X = ica.fit_transform(mixed_X)  # Reconstruct unmixed signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# did it work? let's recreate the sounds\n",
    "wave.write('results/unmix1.wav',rate, np.asarray(unmixed_X[:,0] / np.max(unmixed_X[:,0]) * 14000,\n",
    "    dtype=np.int16) )\n",
    "wave.write('results/unmix2.wav',rate, np.asarray(unmixed_X[:,1] / np.max(unmixed_X[:,1]) * 14000,\n",
    "    dtype=np.int16) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Audio(\"results/unmix1.wav\") # can be either speech or bach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Audio(\"results/unmix2.wav\") # can be either speech or bach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you are interested in a more in-depth, mathematical analysis of the unmixing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sounds good, but how good was it, really?\n",
    "# not trivial to evaluate since ICA only deals with ratios, not amplitudes\n",
    "\n",
    "print('formally, this assumes x = A s in matrix notation')\n",
    "print('s is the separated sources (unmixed_X in the code),')\n",
    "print('A is the \"mixing matrix\",')\n",
    "print('x is the mixed signals, (mixed_X in the code)')\n",
    "\n",
    "calc_A = ica.mixing_  # Get estimated mixing matrix\n",
    "print('\\nunnormalized mixing matrix:\\n',calc_A)\n",
    "# note, ICA can't determine the amplitude of the original mixes, just ratios\n",
    "# also, unmix1 may be bach or speech, no preference for which is first\n",
    "\n",
    "print('\\nthis means:')\n",
    "\n",
    "# renormalize the mixing matrix to be compared with mixing ratios\n",
    "normed_A = np.zeros((2,2))\n",
    "print('the ratio of sources (unmix1:unmix2) in mix 1 is:',\n",
    "      (calc_A[0,1] / calc_A[1,1]) / (calc_A[0,0] / calc_A[1,0]),': 1')\n",
    "print('the ratio of sources (unmix1:unmix2) in mix 2 is:',\n",
    "      (calc_A[0,0] / calc_A[0,1]) / (calc_A[1,1] / calc_A[1,0]),': 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICA noise removal\n",
    "\n",
    "ICA is also use to remove \"artifacts\" from signals\n",
    "This is common in EEG, where you're trying to pick of electric signals from the brain in the scalp, but stray signals (like the 60 Hz from power lines, or electical signals from eye blinks) may mix into a signal.\n",
    "\n",
    "Here is a quick demo showing how the same algorithm as above can be used to remove unwanted artifacts.\n",
    "\n",
    "In this particular example, we are interested in a signal that is made up of a sum of sinusoids, but unfortunately a sawtooth wave was \"accidentally\" mixed in the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example adapted from the sklearn blind source separation example\n",
    "# http://scikit-learn.org/stable/auto_examples/decomposition/plot_ica_blind_source_separation.html#sphx-glr-auto-examples-decomposition-plot-ica-blind-source-separation-py\n",
    "\n",
    "import scipy.signal\n",
    "\n",
    "np.random.seed(10)\n",
    "n_samples = 2000\n",
    "time = np.linspace(0, 8, n_samples)\n",
    "\n",
    "s1 = np.sin(2 * time)  # Signal 1 : sinusoidal signal\n",
    "s2 = np.sin(3 * time)  # Signal 2 : square signal\n",
    "s3 = scipy.signal.sawtooth(2 * np.pi * time)  # Signal 3: saw tooth signal\n",
    "\n",
    "S = np.c_[s1, s2, s3]\n",
    "S += 0.2 * np.random.normal(size=S.shape)  # Add noise\n",
    "\n",
    "S /= S.std(axis=0)  # Standardize data\n",
    "# Mix data\n",
    "A = np.array([[1, 1, 1], [0.5, 2, 1.0], [1.5, 1.0, 2.0]])  # Mixing matrix\n",
    "X = np.dot(S, A.T)  # Generate observations\n",
    "\n",
    "# Compute ICA\n",
    "ica = sklearn.decomposition.FastICA(n_components=3)\n",
    "S_ = ica.fit_transform(X)  # Reconstruct signals\n",
    "A_ = ica.mixing_  # Get estimated mixing matrix\n",
    "\n",
    "# ------------------------------------------\n",
    "# the part that removes one of the independent components - in this case sawtooth noise\n",
    "# ------------------------------------------\n",
    "# remixing after removing one of the components (can't tell ahead which, have to observe)\n",
    "S_clean = S_.copy()\n",
    "S_clean[:,2] = 0     # assuming that is the number of the sawtooth component\n",
    "X_clean = ica.inverse_transform(S_clean)\n",
    "\n",
    "# We can `prove` that the ICA model applies by reverting the unmixing.\n",
    "assert np.allclose(X, np.dot(S_, A_.T) + ica.mean_)\n",
    "\n",
    "# For comparison, compute PCA\n",
    "pca = sklearn.decomposition.PCA(n_components=3)\n",
    "H = pca.fit_transform(X)  # Reconstruct signals based on orthogonal components\n",
    "\n",
    "#Plot results\n",
    "\n",
    "py.figure(figsize=(9,15))\n",
    "\n",
    "models = [X, S_, X_clean, H]\n",
    "names = ['Recorded signals with an artifact (sawtooth \"noise\")',\n",
    "         'ICA recovered signals (notice the sawtooth?)',\n",
    "         'Recorded signals without artifact (sawtooth \"noise\" removed)',\n",
    "         'PCA recovered signals (a.k.a, why PCA won''t help here)']\n",
    "colors = ['red', 'steelblue', 'orange']\n",
    "\n",
    "for ii, (model, name) in enumerate(zip(models, names), 1):\n",
    "    py.subplot(5, 1, ii)\n",
    "    py.title(name)\n",
    "    for sig, color in zip(model.T, colors):\n",
    "        py.plot(sig, color=color)\n",
    "\n",
    "py.subplots_adjust(0.09, 0.04, 0.94, 0.94, 0.26, 0.46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICA theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how did that work? remember this...\n",
    "\n",
    "## the central limit theorem: \n",
    "“Given certain conditions, the mean (or equivalently, sum) of a sufficiently large number of independent random variables will be approximately normally distributed, regardless of the underlying distribution”\n",
    "\n",
    "It's one reason why heights, weights, IQ, etc tend to be normally distribution. \n",
    "They are combinations of a large number of independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(filename=\"slides/gaussian_distributions.png\",width=\"90%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, roughly, mixing MORE independent variables will tend to make the sum MORE gaussian.\n",
    "\n",
    "ICA, roughly: if we know nothing else and we're looking for original sources or independent mixtures, a good approach to unmixing would be to find the LEAST gaussian combinations.\n",
    "\n",
    "## Let's see this with an easy-to-visualize example...\n",
    "(we're doing 2D here, but that's only because it's hard to draw 64D, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# unknown to the algorithm, we'll start with two original signals, mixed in the same data set\n",
    "# in this case, X_orig is 0 in one component and a nongaussian distribution in the other\n",
    "\n",
    "# (this is similar to the FastICA example given in the sklearn documentation)\n",
    "# http://scikit-learn.org/stable/auto_examples/decomposition/plot_ica_vs_pca.html#sphx-glr-auto-examples-decomposition-plot-ica-vs-pca-py)\n",
    "\n",
    "n = 200\n",
    "np.random.seed(10) # to get repeatable runs\n",
    "\n",
    "X_orig = np.zeros((2,n))\n",
    "for i in range(0,n):\n",
    "    if np.random.random() < 0.5: # half the time\n",
    "        X_orig[0,i] = np.random.uniform(-10,10) # note, important this is NOT gaussian\n",
    "    else:\n",
    "        X_orig[1,i] = np.random.uniform(-10,10) # doesn't have to be the same distribution\n",
    "\n",
    "print('First six samples before noise added:\\n', X_orig[:,0:6])\n",
    "showme = 10\n",
    "        \n",
    "# adding input noise\n",
    "X_orig += np.random.normal(0,0.2,size =(2,n))\n",
    "\n",
    "print('\\nFirst six samples after noise added:\\n', X_orig[:,0:6])\n",
    "\n",
    "# now to plot\n",
    "py.figure(figsize=(8,3))\n",
    "py.bar(np.arange(0,showme) - 0.1, X_orig[0,0:showme], width=0.2, \n",
    "    color='b', label='source 1')\n",
    "py.bar(np.arange(0,showme) + 0.1, X_orig[1,0:showme], width=0.2, \n",
    "    color='r', label='source 2')\n",
    "py.xlim((0,10))\n",
    "py.legend()\n",
    "py.title('First ten values with added noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# but the world will mix them without telling us which is which!\n",
    "\n",
    "# shhhhh we'll mix them at ratios depending on an angle (helpful to visualize later)\n",
    "angle1 = 30\n",
    "angle2 = 60\n",
    "np.random.seed(9) # to get repeatable runs\n",
    "xmix = np.cos(np.deg2rad(angle1)) * X_orig[0,:] + \\\n",
    "    np.cos(np.deg2rad(angle2)) * X_orig[1,:] + np.random.normal(0,0.4,size =(n)) # adding mixing noise\n",
    "ymix = np.sin(np.deg2rad(angle1)) * X_orig[0,:] + \\\n",
    "    np.sin(np.deg2rad(angle2)) * X_orig[1,:] + np.random.normal(0,0.4,size =(n))\n",
    "mixed_X = np.transpose(np.stack((xmix, ymix)))\n",
    "\n",
    "# plotting the first few samples from the mixtures\n",
    "py.figure(figsize=(8,3))\n",
    "py.bar(np.arange(0,showme) - 0.1, xmix[0:showme], width=0.2, \n",
    "    color='b', label='mix1 (x)')\n",
    "py.bar(np.arange(0,showme) + 0.1, ymix[0:showme], width=0.2, \n",
    "    color='r', label='mix2 (y)')\n",
    "py.xlim((0,10))\n",
    "py.ylim((-10,10))\n",
    "py.legend()\n",
    "py.title('First ten values after being mixed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here on, in our toy example, we don't know how they were originally mixed, but we want to get the original separate signals\n",
    "\n",
    "For a geometric understanding, let's find another way to look at the mixed data. \n",
    "\n",
    "Each sample is a point in space where 'x' is the first mixture and 'y' is the second mixture. \n",
    "\n",
    "(note, only viewable in 2 or 3 dimensions, but most problems have many more dimensions!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.scatter(xmix, ymix)\n",
    "py.axis('equal')\n",
    "py.xlim((-12,12))\n",
    "py.ylim((-12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sweep through directions looking for the directions of maximum variance\n",
    "\n",
    "angles = np.arange(0,180,1)\n",
    "std = np.zeros(angles.shape)\n",
    "\n",
    "proj = np.zeros(xmix.shape)\n",
    "for (a_i, angle) in enumerate(angles):\n",
    "    for i in range(xmix.shape[0]):\n",
    "        proj[i] = xmix[i] * np.cos(np.deg2rad(angle)) + \\\n",
    "            ymix[i] * np.sin(np.deg2rad(angle))\n",
    "    std[a_i] = np.std(proj)\n",
    "\n",
    "py.figure(figsize=(8,3))\n",
    "py.plot(angles, std)\n",
    "py.title('the standard devation along each direction from the center')\n",
    "py.xlabel('angle from horizontal')\n",
    "py.ylabel('standard deviation along that direction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aha! let's do a common factor analysis, PCA! (and see why it doesn't give us what we want)\n",
    "\n",
    "pca = sklearn.decomposition.PCA(n_components=2)\n",
    "pcafit = pca.fit(mixed_X)\n",
    "\n",
    "print('percent of signal explained by each component:',pcafit.explained_variance_ratio_) \n",
    "\n",
    "#print('the PCA component matrix:\\n',pcafit.components_)\n",
    "\n",
    "pc1x = pcafit.components_[0,0]\n",
    "pc1y = pcafit.components_[0,1]\n",
    "\n",
    "pc2x = pcafit.components_[1,0]\n",
    "pc2y = pcafit.components_[1,1]\n",
    "\n",
    "py.figure(figsize=(7,7))\n",
    "py.scatter(xmix, ymix)\n",
    "py.axis('equal')\n",
    "py.xlim((-12,12))\n",
    "py.ylim((-12,12))\n",
    "\n",
    "# plot the PCA axes\n",
    "scale = 10\n",
    "py.plot( (-scale*pc1x,scale*pc1x),\n",
    "    (-scale*pc1y,scale*pc1y), 'b-', label=\"PCA comp 1\")\n",
    "py.plot( (-scale*pc2x,scale*pc2x),\n",
    "    (-scale*pc2y,scale*pc2y), 'r-', label=\"PCA comp 2\")\n",
    "py.legend()\n",
    "py.title('Visualization of PCA dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform the signal along these PCA directions - note, just one line of code!\n",
    "pca_transformed = pcafit.transform(mixed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all of this cell is just to visualize the results\n",
    "\n",
    "# normalize for comparison to the original\n",
    "pca_transformed /= np.max(pca_transformed)\n",
    "pca_transformed *= 10 # since the original was from -10 to 10\n",
    "\n",
    "print('The original data before mixing:')\n",
    "print(X_orig[:,0:7])\n",
    "print('The data transformed along the PCA components:')\n",
    "print(np.transpose(pca_transformed[0:7,:]))\n",
    "\n",
    "print('\\nNote, the relative magnitudes are right along the first PCA component,')\n",
    "print('but the second dimension isn''t very useful/straightforward to distinguishing the source')\n",
    "\n",
    "# plot the PCA components\n",
    "showme = 10\n",
    "py.figure(figsize=(8,3))\n",
    "py.bar(np.arange(0,showme) - 0.1, pca_transformed[0:showme,0], width=0.2, \n",
    "    color='b', label='PCA comp 1')\n",
    "py.bar(np.arange(0,showme) + 0.1, pca_transformed[0:showme,1], width=0.2, \n",
    "    color='r', label='PCA comp 2')\n",
    "py.xlim((0,10))\n",
    "py.ylim((-10,10))\n",
    "py.legend()\n",
    "py.title('First ten samples transformed onto PCA components')\n",
    "\n",
    "# plot the original\n",
    "py.figure(figsize=(8,3))\n",
    "py.bar(np.arange(0,showme) - 0.1, X_orig[0,0:showme], width=0.2, \n",
    "    color='b', label='orig source 1')\n",
    "py.bar(np.arange(0,showme) + 0.1, X_orig[1,0:showme], width=0.2, \n",
    "    color='r', label='orig source 2')\n",
    "py.xlim((0,10))\n",
    "py.ylim((-10,10))\n",
    "py.legend()\n",
    "py.title('The first ten original values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sweep through directions looking for the \"least gaussian\"\n",
    "# in this case we mean kurtosis farthest from 0\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "angles = np.arange(0,180,1)\n",
    "kurtosis = np.zeros(angles.shape)\n",
    "\n",
    "proj = np.zeros(xmix.shape)\n",
    "for (a_i, angle) in enumerate(angles):\n",
    "    for i in range(xmix.shape[0]):\n",
    "        proj[i] = xmix[i] * np.cos(np.deg2rad(angle+90)) + \\\n",
    "            ymix[i] * np.sin(np.deg2rad(angle+90))  \n",
    "            # technically looking at perpendicular projection with the +90\n",
    "    kurtosis[a_i] = scipy.stats.kurtosis(proj)\n",
    "\n",
    "py.figure(figsize=(8,3))\n",
    "py.plot(angles, kurtosis)\n",
    "py.title('the kurtosis along each direction from the center')\n",
    "py.xlabel('angle from horizontal')\n",
    "py.ylabel('kurtosis along that direction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's use ICA to calculate those directions automatically\n",
    "ica = sklearn.decomposition.FastICA(n_components=2, max_iter=5000, random_state=8)\n",
    "# random state is the random seed. Remove for different results each time\n",
    "icafit = ica.fit(mixed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all the rest of this cell is visualizing those components\n",
    "\n",
    "comp_mat = icafit.components_   # dimensions: components x features\n",
    "# print('the (unnormalized \"unmixing\") ica component matrix:\\n',comp_mat)\n",
    "\n",
    "# normalize components to unit vectors for display purposes \n",
    "comp_mat[0,:] = comp_mat[0,:] / np.linalg.norm(comp_mat[0,:])\n",
    "comp_mat[1,:] = comp_mat[1,:] / np.linalg.norm(comp_mat[1,:])\n",
    "# print('normalized component matrix:\\n',comp_mat)\n",
    "\n",
    "# the indepenedent components (note, ICA insensitive to scale and permutation)\n",
    "# \n",
    "ic1x = comp_mat[0,0]\n",
    "ic1y = -comp_mat[1,0]\n",
    "\n",
    "ic2x = comp_mat[0,1]\n",
    "ic2y = -comp_mat[1,1]\n",
    "\n",
    "py.figure(figsize=(7,7))\n",
    "py.scatter(xmix, ymix)\n",
    "py.axis('equal')\n",
    "py.xlim((-12,12))\n",
    "py.ylim((-12,12))\n",
    "\n",
    "# plot the ICA axes\n",
    "scale = 10\n",
    "py.plot( (-scale*ic1x,scale*ic1x),\n",
    "    (-scale*ic1y,scale*ic1y), 'b-', label='ICA component 1')\n",
    "py.plot( (-scale*ic2x,scale*ic2x),\n",
    "    (-scale*ic2y,scale*ic2y), 'r-', label='ICA component 2')\n",
    "py.legend()\n",
    "py.title('Visualization of ICA dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's tranform the signal along those new dimensions - note, just one line of code\n",
    "ica_transformed = icafit.transform(mixed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all of this cell is just to visualize the results\n",
    "\n",
    "# normalize for comparison to the original\n",
    "ica_transformed /= np.max(ica_transformed)\n",
    "ica_transformed *= 10 # since the original was from -10 to 10\n",
    "\n",
    "show_me = 7\n",
    "print('The original data before mixing:')\n",
    "print(X_orig[:,0:show_me])\n",
    "print('\\nThe data transformed along the ICA components:')\n",
    "print(np.transpose(ica_transformed[0:show_me,:]))\n",
    "\n",
    "print('\\nNote, the sources are separated and the magnitudes are right (apart from possibly sign)')\n",
    "\n",
    "# plot the ICA components\n",
    "showme = 10\n",
    "py.figure(figsize=(8,3))\n",
    "py.bar(np.arange(0,showme) - 0.1, ica_transformed[0:showme,0], width=0.2, \n",
    "    color='b', label='ICA comp 1')\n",
    "py.bar(np.arange(0,showme) + 0.1, ica_transformed[0:showme,1], width=0.2, \n",
    "    color='r', label='ICA comp 2')\n",
    "py.xlim((0,10))\n",
    "py.ylim((-10,10))\n",
    "py.legend()\n",
    "py.title('First ten samples transformed along the ICA components')\n",
    "\n",
    "# plot the original\n",
    "py.figure(figsize=(8,3))\n",
    "py.bar(np.arange(0,showme) - 0.1, X_orig[0,0:showme], width=0.2, \n",
    "    color='b', label='orig source 1')\n",
    "py.bar(np.arange(0,showme) + 0.1, X_orig[1,0:showme], width=0.2, \n",
    "    color='r', label='orig source 2')\n",
    "py.xlim((0,10))\n",
    "py.ylim((-10,10))\n",
    "py.legend()\n",
    "py.title('The first ten original values')\n",
    "\n",
    "# plot the ICA components reflected and permuted to match the original\n",
    "py.figure(figsize=(8,3))\n",
    "py.bar(np.arange(0,showme) - 0.1, -ica_transformed[0:showme,1], width=0.2, \n",
    "    color='b', label='- ICA comp 2')\n",
    "py.bar(np.arange(0,showme) + 0.1, -ica_transformed[0:showme,0], width=0.2, \n",
    "    color='r', label='- ICA comp 1')\n",
    "py.xlim((0,10))\n",
    "py.ylim((-10,10))\n",
    "py.legend()\n",
    "py.title('First ten samples transformed by ICA components, adjusted to match original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICA in natural images\n",
    "## why do primary visual cortex neurons behave like they do?\n",
    "\n",
    "In primary visual cortex (aka V1, the yellow part in the image coming up), neurons respond to particular patterns of light and dark in images. Interestingly, these patterns are reasonably well described by a particular mathematical construct - a 2D Gabor funciton.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# that \"idealization\" of a receptive field is not far from the truth\n",
    "\n",
    "# image on the right from:\n",
    "# Jones JP, Palmer LA. An evaluation of the two-dimensional Gabor filter model\n",
    "# of simple receptive fields in cat striate cortex. J Neurophysiol. 1987\n",
    "# Dec;58(6):1233-58.\n",
    "\n",
    "Image(filename=\"slides/v1_receptive_field_intro.png\",width=\"100%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what does this have to do with ICA?\n",
    "\n",
    "We will see that we can understand the neural code, as measured in the brain,\n",
    "as an efficient coding of our natural world.\n",
    "\n",
    "But it is important to be clear what we mean by \"efficient\" (e.g. PCA vs ICA)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first let's see some of our natural images we are collecting from\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import PIL.Image\n",
    "\n",
    "show_these = ['1.tiff','5.tiff','11.tiff'] # there are 1-13.tiff's\n",
    "\n",
    "# read in images and display from array form - fix: could be simpler\n",
    "fig = py.figure(figsize=(8,14))\n",
    "for (i,file) in enumerate(show_these):\n",
    "    py.subplot(3,1,i+1)\n",
    "    img = PIL.Image.open('data/natural_images/'+file)\n",
    "    py.imshow(img, cmap=py.cm.Greys_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# time to collect some small random patches from those images\n",
    "\n",
    "def collect_natural_patches(num_patches = 100000, patch_width = 8):\n",
    "  \"\"\" collects image patches\n",
    "  the natural images are from a specific folder of 13 .tiff files\"\"\"\n",
    "\n",
    "  max_tries = num_patches * 50\n",
    "  image_width = 200\n",
    "  \n",
    "  img_first_patch = 0 # the first patch number accepted from an image\n",
    "  img_first_try = 0 # the first attempt to take a patch from the image\n",
    "  patch_cnt = 0 # number of collected patches\n",
    "  try_cnt = 0 # number of attempted collected patches\n",
    "  num_pixels = patch_width * patch_width\n",
    "\n",
    "  patch_sample = np.zeros([patch_width,patch_width],float)\n",
    "  patch = np.zeros([num_pixels,1],float)\n",
    "  \n",
    "  img_patches = np.zeros([num_pixels,num_patches],float)\n",
    "\n",
    "  # change the image sampled from\n",
    "  nat_img_cnt = 1  \n",
    "  image = PIL.Image.open('data/natural_images/' + str(nat_img_cnt) + '.tiff')\n",
    "  image = np.asarray(image, 'double').transpose()  \n",
    "  # normalizing the image\n",
    "  image -= image.mean()\n",
    "  image /= image.std()\n",
    "      \n",
    "  # collect the patches\n",
    "  while patch_cnt < num_patches and try_cnt < max_tries:\n",
    "    try_cnt += 1  # number of total patches attempted\n",
    "\n",
    "    if (try_cnt - img_first_try) > max_tries/12 or \\\n",
    "      (patch_cnt - img_first_patch) > num_patches/12:\n",
    "      # change the image sampled from\n",
    "      nat_img_cnt += 1\n",
    "      image = PIL.Image.open('data/natural_images/' + str(nat_img_cnt) + '.tiff')\n",
    "      image = np.asarray(image, 'double').transpose()        \n",
    "      # normalizing the image\n",
    "      image -= image.mean()\n",
    "      image /= image.std()\n",
    "      \n",
    "      img_first_patch = patch_cnt\n",
    "      img_first_try = try_cnt\n",
    "    \n",
    "      # update on every switch of images\n",
    "      print (int(100 * float(patch_cnt)/num_patches),' percent complete')\n",
    "    \n",
    "    px = np.random.randint(0,image_width - patch_width)\n",
    "    py = np.random.randint(0,image_width - patch_width)\n",
    "        \n",
    "    patch_sample = image[px:px+patch_width,py:py+patch_width].copy()\n",
    "    patch_std = patch_sample.std()\n",
    "    \n",
    "    if patch_std > 0.0: # > 0 to remove blank/uninteresting patches for speed\n",
    "      # create the patch vector     \n",
    "      patch = np.reshape(patch_sample, num_pixels)     \n",
    "      patch = patch - np.mean(patch)         \n",
    "      img_patches[:,patch_cnt] = patch.copy()\n",
    "      patch_cnt += 1\n",
    "  return img_patches\n",
    "        \n",
    "patches_mat = collect_natural_patches(num_patches = 100000, patch_width = 8)\n",
    "print('\\nshape of the extracted image patch data:', patches_mat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's look at some of those patches\n",
    "\n",
    "def show_patches_mat(pre_patches, show_patch_num = 16, display=True):\n",
    "  \"\"\" this function generates a 2D array to display image patches (assuming square) \"\"\"\n",
    "  \n",
    "  patches = pre_patches\n",
    "    \n",
    "  tot_patches = patches.shape[1]\n",
    "  data_dim = patches.shape[0]\n",
    "  patch_width = int(np.round(np.sqrt(data_dim)))\n",
    "  \n",
    "  # extract show_patch_num patches\n",
    "  disp_patch = np.zeros([data_dim, show_patch_num], float)\n",
    "  for i in range(0,show_patch_num):\n",
    "    patch_i = i * tot_patches // show_patch_num\n",
    "  \n",
    "    patch = patches[:,patch_i].copy()\n",
    "    pmax  = patch.max()\n",
    "    pmin = patch.min()\n",
    "    # fix patch range from min to max to 0 to 1\n",
    "    if pmax > pmin: \n",
    "      patch = (patch - pmin) / (pmax - pmin)\n",
    "    disp_patch[:,i] = patch.copy()\n",
    "\n",
    "  bw = 5    # border width\n",
    "  pw = patch_width\n",
    "  \n",
    "  patches_y = int(np.sqrt(show_patch_num))\n",
    "  patches_x = int(np.ceil(float(show_patch_num) / patches_y))\n",
    "  patch_img = disp_patch.max() * np.ones([(pw + bw) * patches_x - bw,\n",
    "    patches_y * (pw + bw) - bw], float)\n",
    "  for i in range(0,show_patch_num): \n",
    "    y_i = i // patches_y\n",
    "    x_i = i % patches_y\n",
    "\n",
    "    reshaped = disp_patch[:,i].reshape((pw,pw))\n",
    "    full_patch = np.zeros([pw, pw], float)\n",
    "    full_patch[0:pw,:] = reshaped[:,:].copy()\n",
    "    patch_img[x_i*(pw+bw):x_i*(pw+bw)+pw,y_i*(pw+bw):y_i*(pw+bw)+pw] = full_patch\n",
    "  \n",
    "  if display:\n",
    "    py.bone()\n",
    "    py.imshow(patch_img.T, interpolation='nearest')\n",
    "    py.axis('off')\n",
    "  return\n",
    "\n",
    "show_patches_mat(patches_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## receptive fields, if PCA compression was the kind of \"efficient\" we wanted...\n",
    "\n",
    "PCA would be a good choice if we wanted to minimize the number of neurons in the brain\n",
    "\n",
    "PCA (aka factor analysis) is good for finding a low-dimensional description. Good for compressing the number of bits needed in a representation (or in this case neurons needed to encode a patch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# finding PCA components\n",
    "\n",
    "pcatemp = sklearn.decomposition.PCA(n_components=25)\n",
    "pcafit = pcatemp.fit(np.transpose(patches_mat))\n",
    "\n",
    "print('Quality of image representation using only 40% as much data per patch',\n",
    "      '\\n(using only responses along these 25 components instead of the full 64 dimensions):',\n",
    "      '\\n',np.sum(100*pcafit.explained_variance_ratio_),'%')\n",
    "\n",
    "print('\\nPercentage of data explained by each filter:\\n',100*pcafit.explained_variance_ratio_)\n",
    "\n",
    "pca_comp = pcafit.components_\n",
    "show_patches_mat(np.transpose(pca_comp), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# but remember what receptive field filters look like from real brains\n",
    "\n",
    "Image(filename=\"slides/real_receptive_fields.png\",width=\"30%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receptive fields from ICA, closer to \"efficient\" in the brain\n",
    "\n",
    "ICA isn't about finding a lower dimensional description. The brain has plenty of neurons. \n",
    "The ratio is about 100:1 neurons in V1 compared to axons from the optic nerve\n",
    "so reducing dimensions likely isn't what we're looking for in a \"neurally\" efficient code\n",
    "\n",
    "It may be about finding components which are statistically independent. In other words, each filter response says very little about the likely responses of other filters (note, that's not the case for PCA, where for example, horizontal filters are likely to all fire together with horizontal textures)\n",
    "\n",
    "(Note, independence is a useful feature for group decision making. Would you rather have 10 independent thinkers deciding, or a room full of \"yes people\" in group decision making? Same idea here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# that's nice, but not what we're looking for.\n",
    "# how about if we look for components that give us the most independent information\n",
    "# (note, this is with only 100,000 8x8 patches, so results may not look clean)\n",
    "\n",
    "# finding ICA components\n",
    "\n",
    "icatemp = sklearn.decomposition.FastICA(n_components=50) # note, sensitive to n_components\n",
    "icafit = icatemp.fit(np.transpose(patches_mat))\n",
    "\n",
    "ica_comp = icafit.components_\n",
    "# print('shape of the ica component matrix: ',ica_comp.shape)\n",
    "\n",
    "show_patches_mat(np.transpose(ica_comp), 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... and the same algorithm also describes the early auditory system\n",
    "\n",
    "1. Take clips of \"natural sounds\" (long story about what that means)\n",
    "2. Efficiently encode them with ICA\n",
    "3. Display the linear filters describing that code (receptive fields, if they were neurons)\n",
    "4. Note the similarities between the derived code and experimentally measured receptive fields\n",
    "\n",
    "The image below is a clip from the following poster\n",
    "\n",
    " Makarious M, Moe G, Albert MV.\n",
    " Application for interactive demonstration of efficient visual and auditory neural codes\n",
    " Society for Neuroscience (SfN 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(filename=\"slides/efficient_coding_poster_clip.png\",width=\"100%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
